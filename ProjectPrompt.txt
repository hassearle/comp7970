# comp7970

warning: LF will be replaced by CRLF in Dataset/com-dblp.ungraph.txt.
The file will have its original line endings in your working directory.

COMP7970 Group Project
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Due Dec 14 by 4:59pm  
Points 20  // Very imp
Submitting a file upload Available Sep 26 at 12am - Dec 14 at 4:59pm 
3 months
The course project will consist of four parts: 
	Part 1 (proposals), 
	Part 2 (submissions), 
	Part 3 (presentations),  
	Part 4 (final reports for graduate students). 
We assume that you will work on it in teams of 3-4 people for one group. 
If you wish to work individually or in a group of two people, please check
with the instructor.

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Important dates:

Project proposals due: Sunday, October 15, 11:59pm
Project submissions due: Thursday, November 30, 11:59pm
Project presentations: December 1, the week of December 4-8
Final reports due: Thursday, December 14, 4:59pm
 
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Objectives. 

Projects are intended to give students the opportunity to explore 
ideas or directions in data mining (e.g., frequent itemset mining,
clustering, classification, ranking, recommendation, similarity search), 
to discover interesting pattern and knowledge from available application
datasets.

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Project proposals 

are to be 2 pages in length and will include the particular problem to be 
considered, the algorithm to be implemented, the datasets to be evaluated, 
where and how to get the data, the evaluation measures to be reported, and
a list of several references that will support the project. The bottom of 
this document lists available data mining algorithms and the original 
papers. All chosen algorithms are classical data mining algorithms. 
If you meet issues and difficulties during proposal development, you could 
discuss with the TA or the instructor during office hours.

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Project submissions 

will include your data and code, configuration, experiment results ncluding 
figures and tables, and readme file to state how to run your code. Please 
first use the same datasets and evaluation measures used in corresponding 
papers. For undergraduate projects and graduate projects which do not 
provide available datasets and evaluation measures, use the attached two
datasets (Dataset.zipView in a new window) as your data matrices or 
adjacency matrices. Alternative evaluation measures are Dunn index, 
Silhouette coefficient, and Davies-Bouldin index for clustering, Macro-F1,
Micro-F1, and Hamming Loss for classification, MAE and RMSE for 
recommendation.

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Project presentations 

(15 minutes for each project) will include problem definition, algorithm 
introduction, program demonstration, experiment results, and Q/A.

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Final reports 

for graduate students are to be 5 pages in length and will include the 
contents in the proposals too, the main ideas of the algorithm, the main 
steps of the algorithm, the configuration of experiment environment, the 
analysis of the experiment results, the strong points of the algorithm, and 
the potential weak points of the algorithm. Final reports are also expected 
to show some new ideas about extensions of existing data mining algorithms 
or to develop new algorithms to solve real world problems.

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Requirements. Your submission should address the following issues:

	* Implement the source codes by yourselves
	* Effectiveness test on one small dataset: report two scores of 
		evaluation measures
	* Efficiency test on one small dataset: report running time
	* Scalability test on one large dataset (optional): report two scores 
		of evaluation measures, report running time

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Requirements. Your presentation and final report should clarify the 
following issues:

	* What is the problem and datasets addressed by the project?
	* What is the data mining algorithm implemented?
	* What are the knowledge or pattern discovered from the project?
	* What are your evaluations and ideas for extensions and improvements?
 
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Evaluation. 

Every member in a team gets the same score. No copying or sharing of 
source codes from paper authors or other people is allowed. The basic 
features of graduate students will be normalized into the range between 0 
and 20 points on a pro rata basis.

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Basic features:

	* Project proposals (5 points)
	* Project submissions (10 points)
	* Project presentations (5 points)
	* Final reports (5 points)

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Bonus features:

	* Scalability test on one large dataset (10 points)
	* Undergraduate students implement graduate projects (10 points)
 
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Project topics.

	Undergraduate projects: 
		
		All projects are from the textbook (J. Han, M. Kamber, and J. Pei.
		Data Mining: Concepts and Techniques. Morgan Kaufmann, 3rd ed.,2011)

		* Frequent Itemset Mining (Apriori, FP-Growth)
		* Classification (Decision Tree, Bayes Classification) 
		* Clustering (k-Means, BIRCH, DBSCAN)

	Graduate projects:

		* Clustering (k-Means++ [1], SCAN [2], k-SNAP [3])
		* Classification (LP [4], EdgeCluster [5], SCRN [6])
		* Ranking (RankClus [7])
		* Recommendation (NMF [8], SVD++ [9], TrustWalker [10])
		* Similarity Search (Fast RWR [11], Single-Pair SimRank [12])
 
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

References

[1] D. Arthur and S. Vassilvitskii. k-Means++: The Advantages of Careful Seeding. In SODA, 2007.
[2] X. Xu, N. Yuruk, Z. Feng, and T. A. J. Schweiger. Scan: a structural clustering algorithm for networks. In KDD, 2007.
[3] Y. Tian, R. A. Hankins, and J. M. Patel. Efficient aggregation for graph summarization. In SIGMOD, 2008.
[4] X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised learning using Gaussian fields and harmonic functions. In ICML, 2003.
[5] L. Tang and H. Liu. Scalable Learning of Collective Behavior Based on Sparse Social Dimensions. In CIKM, 2009.
[6] X. Wang and G. Sukthankar. Multi-Label Relational Neighbor Classification using Social Context Features. In KDD, 2013.
[7] Y. Sun, J. Han, P. Zhao, Z. Yin, H. Cheng, T. Wu. RankClus: Integrating Clustering with Ranking for Heterogeneous Information Network Analysis. In EDBT, 2009.
[8] D. D. Lee and H. S. Seung. Algorithms for Non-negative Matrix Factorization. In NIPS, 2001.
[9] Y. Koren. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In KDD, 2008.
[10] M. Jamali and M. Ester. TrustWalker: A Random Walk Model for Combining Trust-based and Item-based Recommendation. In KDD, 2009.
[11] H Tong, C. Faloutsos, and J.-Y. Pan. Fast Random Walk with Restart and Its Applications. In ICDM, 2006.
[12] P. Li, H. Liu, J. X. Yu, J. He, and X. Du. Fast Single-Pair SimRank Computation. In SDM, 2010.